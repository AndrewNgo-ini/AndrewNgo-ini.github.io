---
title: "Explain math"
date: 2022-11-14T14:51:28+07:00
draft: false
---
I have been started late, back to highschool all I did was just crunching all tons of numbers without understand it despite the fact that i'm pretty good at doing it. But since then, and from now on. Theres something different in my thought. I dont want to do thing that i don't understand. I always crave for at least an intuition about hows it work. When started doing Machine Learning problems. Math is quite an essential skills that everybody has to learn, to some extent I supposed. The three components they said and I thought include Linear algebrea, Calculus and Probability Statiscial. If I had to explain the most practical knowledge in math. below are some of the concept I found it pretty needed using it or not 
I. Linear Algebrea 
There is a course that I took about what math we need in linear algebra to use in Machine learning, and honestly they're what we need but I need to make a note to summarize it and also make my knowledge stronger 
1. What is vector 
2. What is Linear combination 
3. What is Matrix and how is it actually 
4. What is determinant and what kind of job it do to help us 
5. Eigenvectors, eigenvalues. Should we learn it, does it apply immeditely 
6.Still forget. why dotting is the projection? 
7. All the relation of dot product? 
II. Calculus 
1. Derivatetive, anti derivative? 
1.1 Slope? Rise over run? 
2. Gradient? 
3. A vector of gradient (jacobian?) 
4. What to do with Jacobian Matrix 
5. How does that mean when we say that the vector point at steepest slope 
https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/why-the-gradient-is-the-direction-of-steepest-ascent 
6. How does an jacobian matrix transform an vector?